{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification, Trainer, TrainingArguments\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Map: OrderedDict([('O', 0), ('B-LOC', 1), ('B-ORG', 2), ('B-PER', 3), ('I-LOC', 4), ('I-ORG', 5), ('I-PER', 6)])\n",
      "Number of Labels: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 指定文件路径\n",
    "train_file_path = 'data/train.json'  # 训练集文件路径\n",
    "test_file_path = 'data/test.json'    # 验证集（或测试集）文件路径\n",
    "\n",
    "# 加载数据集\n",
    "dataset = load_dataset('json', data_files={'train': train_file_path, 'test': test_file_path})\n",
    "\n",
    "label_map, label_nums = generate_label_map_and_count(train_file_path)\n",
    "print(\"Label Map:\", label_map)\n",
    "print(\"Number of Labels:\", label_nums)\n",
    "\n",
    "# 加载模型\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-chinese')\n",
    "model = BertForTokenClassification.from_pretrained('bert-base-chinese', num_labels=label_nums)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 应用预处理到加载的数据集\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128, return_offsets_mapping=True)\n",
    "    labels = []\n",
    "    \n",
    "    for i, doc_labels in enumerate(examples[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # 获取每个令牌对应的词汇ID\n",
    "        label_ids = [-100 if id is None else label_map[doc_labels[id]] for id in word_ids]\n",
    "        labels.append(label_ids)\n",
    "    \n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    tokenized_inputs.pop(\"offset_mapping\") # 不需要返回偏移量映射给模型\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评估函数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metric = evaluate.load('seqeval')\n",
    "label_map = {'O': 0, 'B-LOC': 1, 'B-ORG': 2, 'B-PER': 3, 'I-LOC': 4, 'I-ORG': 5, 'I-PER': 6}\n",
    "# 反转label_map，用于ID到标签的转换\n",
    "id_to_label = {id: label for label, id in label_map.items()}\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    seqeval_metric = evaluate.load('seqeval')\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=2)\n",
    "    \n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    for i, label_seq in enumerate(labels):\n",
    "        true_seq = []\n",
    "        pred_seq = []\n",
    "        for j, label_id in enumerate(label_seq):\n",
    "            if label_id != -100:  # 忽略特殊的-100标签\n",
    "                true_seq.append(id_to_label.get(label_id, \"O\"))\n",
    "                \n",
    "                pred_id = predictions[i, j]\n",
    "                pred_seq.append(id_to_label.get(pred_id, \"O\"))\n",
    "                    \n",
    "        true_labels.append(true_seq)\n",
    "        pred_labels.append(pred_seq)\n",
    "    \n",
    "    results = seqeval_metric.compute(predictions=pred_labels, references=true_labels, scheme=\"IOB2\", mode=\"strict\")\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['labels', 'text', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "['labels', 'text', 'input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(tokenized_dataset[\"train\"].column_names)\n",
    "tokenized_dataset[\"train\"][0][\"text\"]\n",
    "tokenized_dataset[\"train\"][0][\"labels\"]\n",
    "print(tokenized_dataset[\"test\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./tmp\",         # 输出目录\n",
    "    num_train_epochs=3,             # 训练轮数\n",
    "    per_device_train_batch_size=8,  # 训练批次大小\n",
    "    per_device_eval_batch_size=16,   # 评估批次大小\n",
    "    warmup_steps=500,               # 预热步数\n",
    "    weight_decay=0.01,              # 权重衰减\n",
    "    logging_dir=\"./logs\",           # 日志目录\n",
    "    logging_strategy='epoch',# 日志记录步数\n",
    "    evaluation_strategy='epoch',    # 评估策略\n",
    "    save_strategy='epoch',          # 保存策略\n",
    "    load_best_model_at_end=True,    # 训练结束时加载最佳模型\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp_app/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17388' max='17388' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17388/17388 19:55, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.080800</td>\n",
       "      <td>0.040567</td>\n",
       "      <td>0.919086</td>\n",
       "      <td>0.883507</td>\n",
       "      <td>0.900946</td>\n",
       "      <td>0.988930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.027100</td>\n",
       "      <td>0.038639</td>\n",
       "      <td>0.920483</td>\n",
       "      <td>0.919157</td>\n",
       "      <td>0.919820</td>\n",
       "      <td>0.990810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>0.036514</td>\n",
       "      <td>0.934890</td>\n",
       "      <td>0.922938</td>\n",
       "      <td>0.928876</td>\n",
       "      <td>0.991904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 初始化Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                         # 使用预处理后初始化的模型\n",
    "    args=training_args,                  # 训练参数\n",
    "    train_dataset=tokenized_dataset[\"train\"], # 训练数据集\n",
    "    eval_dataset=tokenized_dataset[\"test\"],     # 验证/测试数据集\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# 开始训练\n",
    "trainer.train()\n",
    "# 训练结束后手动保存模型\n",
    "trainer.save_model(\"./models/my-bert-chinese-ner\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='273' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  2/273 00:00 < 00:08, 31.57 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.036513760685920715,\n",
       " 'eval_precision': 0.9348896589458325,\n",
       " 'eval_recall': 0.9229384227583723,\n",
       " 'eval_f1': 0.9288756002536922,\n",
       " 'eval_accuracy': 0.9919044956518636,\n",
       " 'eval_runtime': 12.0875,\n",
       " 'eval_samples_per_second': 361.116,\n",
       " 'eval_steps_per_second': 22.585,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 评估模型\n",
    "trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
