{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-24T13:52:39.247267Z",
     "start_time": "2024-03-24T13:52:01.475406Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from transformers import Trainer\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"sentence1\"], examples[\"sentence2\"], truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T13:52:40.308364Z",
     "start_time": "2024-03-24T13:52:39.248245Z"
    }
   },
   "id": "92523147009817c3",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"test_trainer\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T13:52:40.314241Z",
     "start_time": "2024-03-24T13:52:40.309416Z"
    }
   },
   "id": "80a32d10df70f51c",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T13:52:40.317776Z",
     "start_time": "2024-03-24T13:52:40.315948Z"
    }
   },
   "id": "7bad5f80f8318782",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AcceleratorState' object has no attribute 'distributed_type'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m predictions \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokenized_datasets\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mvalidation\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(predictions\u001B[38;5;241m.\u001B[39mpredictions\u001B[38;5;241m.\u001B[39mshape, predictions\u001B[38;5;241m.\u001B[39mlabel_ids\u001B[38;5;241m.\u001B[39mshape)\n",
      "File \u001B[0;32m~/miniconda3/envs/nlp_learn/lib/python3.11/site-packages/transformers/trainer.py:3301\u001B[0m, in \u001B[0;36mTrainer.predict\u001B[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[1;32m   3298\u001B[0m \u001B[38;5;66;03m# memory metrics - must set up as early as possible\u001B[39;00m\n\u001B[1;32m   3299\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_memory_tracker\u001B[38;5;241m.\u001B[39mstart()\n\u001B[0;32m-> 3301\u001B[0m test_dataloader \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_test_dataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_dataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3302\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m   3304\u001B[0m eval_loop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprediction_loop \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39muse_legacy_prediction_loop \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluation_loop\n",
      "File \u001B[0;32m~/miniconda3/envs/nlp_learn/lib/python3.11/site-packages/transformers/trainer.py:944\u001B[0m, in \u001B[0;36mTrainer.get_test_dataloader\u001B[0;34m(self, test_dataset)\u001B[0m\n\u001B[1;32m    941\u001B[0m     dataloader_params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprefetch_factor\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdataloader_prefetch_factor\n\u001B[1;32m    943\u001B[0m \u001B[38;5;66;03m# We use the same batch_size as for eval.\u001B[39;00m\n\u001B[0;32m--> 944\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maccelerator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprepare\u001B[49m\u001B[43m(\u001B[49m\u001B[43mDataLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mdataloader_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/nlp_learn/lib/python3.11/site-packages/accelerate/accelerator.py:1219\u001B[0m, in \u001B[0;36mAccelerator.prepare\u001B[0;34m(self, device_placement, *args)\u001B[0m\n\u001B[1;32m   1208\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   1209\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(obj, torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mModule)\n\u001B[1;32m   1210\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverify_device_map(obj)\n\u001B[1;32m   1211\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistributed_type \u001B[38;5;241m!=\u001B[39m DistributedType\u001B[38;5;241m.\u001B[39mNO\n\u001B[1;32m   1212\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m os\u001B[38;5;241m.\u001B[39menviron\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mACCELERATE_BYPASS_DEVICE_MAP\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfalse\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrue\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1213\u001B[0m     ):\n\u001B[1;32m   1214\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1215\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou can\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt train a model that has been loaded with `device_map=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m` in any distributed mode.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1216\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m Please rerun your script specifying `--num_processes=1` or by launching with `python \u001B[39m\u001B[38;5;124m{{\u001B[39m\u001B[38;5;124mmyscript.py}}`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1217\u001B[0m         )\n\u001B[0;32m-> 1219\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistributed_type\u001B[49m \u001B[38;5;241m==\u001B[39m DistributedType\u001B[38;5;241m.\u001B[39mDEEPSPEED:\n\u001B[1;32m   1220\u001B[0m     model_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m   1221\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m args:\n",
      "File \u001B[0;32m~/miniconda3/envs/nlp_learn/lib/python3.11/site-packages/accelerate/accelerator.py:509\u001B[0m, in \u001B[0;36mAccelerator.distributed_type\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    507\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[1;32m    508\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdistributed_type\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistributed_type\u001B[49m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'AcceleratorState' object has no attribute 'distributed_type'"
     ]
    }
   ],
   "source": [
    "# predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
    "# print(predictions.predictions.shape, predictions.label_ids.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T13:52:40.400252Z",
     "start_time": "2024-03-24T13:52:40.318650Z"
    }
   },
   "id": "39bff55cc7467ae6",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"glue\", \"mrpc\")\n",
    "preds = np.argmax(predictions.predictions, axis=1)\n",
    "metric.compute(predictions=preds, references=predictions.label_ids)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T13:52:40.401417Z",
     "start_time": "2024-03-24T13:52:40.401345Z"
    }
   },
   "id": "c769806fecfe88d6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5158bbab7e76d9b0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9d4cfe776d26923a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "98a2f791682e1d7f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
