{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7138d8cf7c956ade",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T05:33:12.376143Z",
     "start_time": "2024-03-17T05:33:08.256402Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple/\r\n",
      "Requirement already satisfied: sentencepiece in ./miniconda3/lib/python3.10/site-packages (0.1.99)\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://hf-mirror.com\n",
      "Number of GPUs available: 1\n",
      "CUDA version: 12.1\n",
      "Device name: NVIDIA RTX A6000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# cache_dir = \"/Users/yangye/models\"\n",
    "\n",
    "\n",
    "# 设置环境变量\n",
    "# os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "\n",
    "# 检查环境变量是否设置成功\n",
    "print(os.environ[\"HF_ENDPOINT\"])\n",
    "# 设置 CUDA_VISIBLE_DEVICES 环境变量\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA is not available. Check your installation and try again.\")\n"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-17T05:33:12.388052Z",
     "start_time": "2024-03-17T05:33:12.379894Z"
    }
   },
   "id": "initial_id",
   "execution_count": 170
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'POSITIVE', 'score': 0.9598048329353333}]"
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T05:33:14.801186Z",
     "start_time": "2024-03-17T05:33:12.390216Z"
    }
   },
   "id": "12c631c3e06e706f",
   "execution_count": 171
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'POSITIVE', 'score': 0.9598048329353333},\n {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    "    [\"I've been waiting for a HuggingFace course my whole life.\", \"I hate this so much!\"]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T05:33:16.777143Z",
     "start_time": "2024-03-17T05:33:14.803268Z"
    }
   },
   "id": "da711919caa72e6d",
   "execution_count": 172
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'POSITIVE', 'score': 0.9988415837287903}]"
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    " \"I am lingtao master\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T05:33:17.609041Z",
     "start_time": "2024-03-17T05:33:16.778785Z"
    }
   },
   "id": "d4cb8ecb25c00ed",
   "execution_count": 173
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'NEGATIVE', 'score': 0.9993966817855835}]"
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    "    \"I am sading\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T05:33:18.238595Z",
     "start_time": "2024-03-17T05:33:17.610574Z"
    }
   },
   "id": "6b8c895c1a4dd850",
   "execution_count": 174
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'NEGATIVE', 'score': 0.9995057582855225}]"
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    "    \"I get a apple from toilet\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T05:33:18.656591Z",
     "start_time": "2024-03-17T05:33:18.240152Z"
    }
   },
   "id": "f5caa2b7b0a5e3e4",
   "execution_count": 175
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'POSITIVE', 'score': 0.9947863817214966}]"
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    "    \"I get a apple from a little boy\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T05:33:19.483194Z",
     "start_time": "2024-03-17T05:33:18.657891Z"
    }
   },
   "id": "f66fe02c9bd149dd",
   "execution_count": 176
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'NEGATIVE', 'score': 0.8768509030342102}]"
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    "    \"我是孔令涛\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T05:33:20.367535Z",
     "start_time": "2024-03-17T05:33:19.485308Z"
    }
   },
   "id": "9e57131ce2d4c305",
   "execution_count": 177
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 文本分类"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T05:33:20.376385Z",
     "start_time": "2024-03-17T05:33:20.372106Z"
    }
   },
   "id": "98148b01e1ed60b7",
   "execution_count": 178
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://hf-mirror.com/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'sequence': 'This is a course about the Transformers library',\n 'labels': ['education', 'business', 'politics'],\n 'scores': [0.8445960283279419, 0.11197628080844879, 0.043427709490060806]}"
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier(\n",
    "    \"This is a course about the Transformers library\",\n",
    "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T05:33:27.571146Z",
     "start_time": "2024-03-17T05:33:20.377775Z"
    }
   },
   "id": "41ac3b4599b3ff03",
   "execution_count": 179
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'sequence': '我是西安交通大学的孔令涛硕士',\n 'labels': ['education', 'business', 'politics'],\n 'scores': [0.858680009841919, 0.11062318831682205, 0.030696818605065346]}"
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    "    \"我是西安交通大学的孔令涛硕士\",\n",
    "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T05:33:28.659779Z",
     "start_time": "2024-03-17T05:33:27.572355Z"
    }
   },
   "id": "1a70dcf65e7925e6",
   "execution_count": 180
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'sequence': '我是令涛硕士。',\n 'labels': ['business', 'education', 'politics'],\n 'scores': [0.4734025001525879, 0.39843112230300903, 0.1281663328409195]}"
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    "    \"我是令涛硕士。\",\n",
    "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T05:33:32.136746Z",
     "start_time": "2024-03-17T05:33:28.661290Z"
    }
   },
   "id": "d38de6915243e6b6",
   "execution_count": 181
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 文本生成"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b58aae891307302d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://hf-mirror.com/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'generated_text': 'In this course, we will teach you how to get better than most people.\\n\\nYou will learn how you will build rapport with people as you get better at making friends and getting along with people.\\n\\nYou will learn why \"friends\"'}]"
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\")\n",
    "generator(\"In this course, we will teach you how to\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T05:33:35.196389Z",
     "start_time": "2024-03-17T05:33:32.137865Z"
    }
   },
   "id": "4ddae9e5276497c9",
   "execution_count": 182
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'generated_text': '我是令涛硕士，我就读于西安交大。也可是经也不是由其对'}]"
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"我是令涛硕士，我就读于西安交大。\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T05:33:37.163368Z",
     "start_time": "2024-03-17T05:33:35.197893Z"
    }
   },
   "id": "103c12cb46fd14d2",
   "execution_count": 183
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'generated_text': 'I like eat apple \"\\n\\nThe woman\\'s expression changed to one that suggested she had a very different feeling coming from her daughter\\'s head.\\n\\n\"I have to say, my daughter will never forget, we\\'re a family that makes'}]"
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"I like eat apple \")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T05:33:42.837660Z",
     "start_time": "2024-03-17T05:33:37.164871Z"
    }
   },
   "id": "9b0805c5c79b7db8",
   "execution_count": 184
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'generated_text': 'In this course, we will teach you how to get out of bed, to get out of bed, and to stay in the same way that you'},\n {'generated_text': 'In this course, we will teach you how to be comfortable with taking an effective and effective approach to yoga. We will learn the best ways to become'}]"
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
    "generator(\n",
    "    \"In this course, we will teach you how to\",\n",
    "    max_length=30,\n",
    "    num_return_sequences=2,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T05:33:44.599879Z",
     "start_time": "2024-03-17T05:33:42.839010Z"
    }
   },
   "id": "fc528ca6e5e1e2ed",
   "execution_count": 185
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'generated_text': 'In this course, we will teach you how to teach with a great deal the importance of having these skills and how to create fun and rewarding work that can enrich your life.'},\n {'generated_text': 'In this course, we will teach you how to practice the three essential parts of meditation:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThe practice begins as follows:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThe practice begins as follows:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThe practice begins as follows:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThe practice begins as follows:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThe practice begins as follows:\\n\\n\\n\\n\\n\\n\\n\\n\\nThe practice begins as follows:\\n\\n\\n\\n\\n\\n\\n\\n\\nThe practice starts as follows:\\n\\n\\n\\n\\n\\n\\n\\n\\nThe practice begins as follows:\\n\\n\\n\\n\\n\\n\\nThe practice begins as follows:\\n\\n\\n\\n\\n\\n\\n\\nThe practice begins as follows:\\n\\n\\n\\n\\n\\nThe practice begins as follows:\\n\\n\\n\\n\\n\\n\\n\\n\\nThe practice begins as follows:\\n\\n\\n\\n\\n\\nThe practice begins as follows:\\n\\n\\n\\n\\n\\n\\n\\nThe practice begins as follows:\\n\\n\\n\\nThe practice begins as follows:\\n\\n\\n\\n\\nThe practice begins as follows:\\n\\n\\n\\n\\n\\nThe practice begins as follows:\\n\\n\\n\\n\\n\\n\\nThe practice'},\n {'generated_text': 'In this course, we will teach you how to convert, learn and support your children, and teach the best practices you can to change your personal life.'},\n {'generated_text': \"In this course, we will teach you how to write and write Java code in Java which is very basic!\\n\\nIn this course, we will look at how to write Java code as well as Java Java Java Code, which it covers by building and creating one of the following classes:\\nTo build Java code, you must create classes using Java methods, which will become called Object, which in practice will become available as Java code.\\nYou must also define Java methods using Java as an instance of java.JPM, which is the class that is used by the Java object:\\njava.JPM: java.jpm\\nYou have this example (app.java:8.0) which you have created for you in a single Java class:\\njava.JPM: java.jpm\\nYou have implemented and exported all of the above classes by using a Java object called object().\\nJava objects are created based on code called JavaObject() which is used to invoke the Java object to process the JavaScript code.\\nThe class is created based on code called JavaObject() which is used from the class:\\njava.JPM: java.jpm\\nYou created the same class with Java as the class, using the Java object:\\njava.JPM: java.jpm\\nThat's it!\\nJava is a little different from Java when you add classes. You will need to instantiate Java code through a method using Java as an instance\"},\n {'generated_text': 'In this course, we will teach you how to apply to a class of about five years, in order to learn how to best use your skills, by studying how to master the subject.\\n\\n\\nI always ask that you do not allow me to say: \"how can you use a lot of skill in the course?\", for example, \"how could you use more skill in a class of over seven years!\" And to say, \"that\\'s the one problem in those classes that you must solve and you may be very interested in learning about the subject that I will teach in future courses?\" It does not mean that you do not want to study the subject in the course, but that you learn it to learn how to do it: we would be more interested in learning about how to practice it.\\nIn that course, you will be able to apply to a class of 5 years, as you will be able to learn the subject from there. For these classes, you will need to learn how to manage the student and how to make a difference in the society. All of that is taught here in practice, and you will have to learn how to make progress. We will cover this very matter later, so to be sure, let me know what you think about this topic.\\nI thank you very much for reading this course on the web, thank you to you so much for reading my course on learning.\\nThe courses in this course, in any way, will be offered'},\n {'generated_text': \"In this course, we will teach you how to start your own small business.\\n\\n\\n1. Do not do anything with money.\\n2. Do not sell as much.\\n3. Learn how to run an online business.\\n4. Be smart.\\n5. Have a good conversation with your customers.\\n6. Do not forget about the company's name.\\n7. Pay attention to your surroundings rather than buying what you think is your business plan, so that your customers feel comfortable with being taken seriously in the future.\\nIf you are taking an initial step towards developing your business, you don't want your customers to forget about it. You also don't want you to take your interest in your product or products.\\nYou need to understand that you should never just sell an entire product to an empty line of customers. If you have to sell into the world, you also need to understand how customers are really looking for business plans.\\nThe following course course is only for students and can only be used to create a business plan that will make money.\\nIn this course, you will learn the basics of the business plans, how to start a business plan, how to do it effectively, what is the best way to get started, and how to create a business plan.\\nLearn how to create a financial business plan in a real life environment. This course will teach you how to use an online business and prepare your own business plan.\\nWhen this course\"},\n {'generated_text': 'In this course, we will teach you how to perform this task together.\\n\\n\\n\\nWhat I mean by —I will explain these principles in the course\\nI will discuss my —I will go in on top of all the steps I take to implement this task\\nI will discuss this in a short short video video of this class\\nI will explain how\\nI will discuss this in a short video of this class,\\nI will follow your progress on my learning along the way so I can continue in the next section\\nSo how about you?\\nMy lessons'},\n {'generated_text': \"In this course, we will teach you how to write a long list of useful languages for beginners and are interested in how best to write languages for beginners and are interested in how to use them!\\n\\n\\nFirst-hand, try to understand the basics of these languages. The first thing that comes out of this course are the following:\\nLanguage : English (i.e. German)\\nType : German (i.e. German ) Language : German (i.e. German )\\nYou can learn more about all the following languages as well. In the next course, you will see more of these languages using them!\\nNow, you will notice that when you start playing with these languages, they should look familiar, even if you don't know the actual language here! You will also notice that the examples that they are working on will be familiar. In order to play these languages in your new language, you will have to be aware that the actual language is the original language!\\nThe most important thing to do before getting started with the concepts in order to start learning them!\\nThis next course will be a detailed explanation of the common language by which to learn them, and also about how the concept is implemented. The basic concepts are explained in Chapter 2, of the Introduction to the Common Language.\\nNote that many examples in this course are not complete tutorials, and that the concepts in the course are not meant as a tutorial, so you are advised to read the\"},\n {'generated_text': 'In this course, we will teach you how to use your favourite Android platform to make a seamless experience!'},\n {'generated_text': 'In this course, we will teach you how to create content that will be useful for the purpose of the course.”\\n\\n\\nIf you‡feel free to add your own view, I promise to deliver a tutorial on how you will use content that will be useful for the purpose of the course.'},\n {'generated_text': 'In this course, we will teach you how to use a device to monitor your health and other health issues via a series of mobile devices. Our goal is to make you comfortable by allowing you access to more information that can be found in a single app or app on your device, while helping to provide you with more information on what your health is and what you might not notice when the device is activated.\\n\\n\\n\\n\\n\\n\\n* Android, iOS, and Android\\n\\n* Android, iOS, and Android-based devices (including your phone) are currently not yet available for purchase, but you can purchase your Android devices at any time using our free website.\\n\\n\\nFor more information visit our website:'},\n {'generated_text': 'In this course, we will teach you how to use one of the most complex functions of this course, how you can write a script in real time, and all the related functions which you can use.'},\n {'generated_text': 'In this course, we will teach you how to read this subject in English.\\n\\n\\n\\n\\n\\nCitations and Quotes\\n\\nPlease email me at josh_fletcher.com.'},\n {'generated_text': 'In this course, we will teach you how to build the best Java EE project.'},\n {'generated_text': 'In this course, we will teach you how to write in JavaScript, use JavaScript in mobile, and then make it the next step of learning React over React Over Redux, the other way around.\\n\\n\\n\\n\\nIf you want to learn React over JavaScript, you are already used to the use of React over Redux. The language is made up of two features:'},\n {'generated_text': 'In this course, we will teach you how to make a clean, clean kitchen and clean the kitchen, and give you the ability to make clean, healthy kitchen and clean the kitchen, as well as create your own recipes that allow you to make beautiful kitchen dishes, and make that a good living!'},\n {'generated_text': 'In this course, we will teach you how to get the perfect experience for learning how to build effective communication with the community and provide tips on the importance of networking.'},\n {'generated_text': 'In this course, we will teach you how to use real language in your day and night.'},\n {'generated_text': 'In this course, we will teach you how to learn: Read Less, Do Go There, and Do Get More.'},\n {'generated_text': 'In this course, we will teach you how to use an HTML5 based browser and how to create one with a minimal HTML5 based browser. Our web browser and web browser will help you to create one with HTML5 based browser.\\n\\n\\n\\nNext Chapter: Use HTML5 as a HTML5 based browser\\nNow if you plan to run this course we will use HTML5 based browser, if you cannot get a web browser to do this or if your HTML5 based browser needs HTML5 based browser (the main reasons behind it are shown below).\\n1.)'}]"
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\", model=\"distilgpt2\",device=0)\n",
    "generator(\n",
    "    \"In this course, we will teach you how to\",\n",
    "    max_length=300,\n",
    "    num_return_sequences=20,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T05:33:47.086426Z",
     "start_time": "2024-03-17T05:33:44.602187Z"
    }
   },
   "id": "6d4132549c443a72",
   "execution_count": 186
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilroberta-base and revision ec58a5b (https://hf-mirror.com/distilbert/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'score': 0.19619712233543396,\n  'token': 30412,\n  'token_str': ' mathematical',\n  'sequence': 'This course will teach you all about mathematical models.'},\n {'score': 0.04052708297967911,\n  'token': 38163,\n  'token_str': ' computational',\n  'sequence': 'This course will teach you all about computational models.'}]"
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "\n",
    "unmasker = pipeline(\"fill-mask\",device=0)\n",
    "unmasker(\"This course will teach you all about <mask> models.\", top_k=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T05:33:48.183088Z",
     "start_time": "2024-03-17T05:33:47.088720Z"
    }
   },
   "id": "4f6dc5d3e0188869",
   "execution_count": 187
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'score': 0.14672788977622986,\n  'token': 48827,\n  'token_str': '上',\n  'sequence': '我早上喜欢吃苹果和上。'},\n {'score': 0.12378136068582535,\n  'token': 47643,\n  'token_str': '中',\n  'sequence': '我早上喜欢吃苹果和中。'}]"
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "[{'score': 0.14672788977622986,\n  'token': 48827,\n  'token_str': '上',\n  'sequence': '我早上喜欢吃苹果和上。'},\n {'score': 0.12378136068582535,\n  'token': 47643,\n  'token_str': '中',\n  'sequence': '我早上喜欢吃苹果和中。'}]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"我早上喜欢吃苹果和<mask>。\", top_k=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T12:59:49.352004Z",
     "start_time": "2024-03-17T05:33:48.185582Z"
    }
   },
   "id": "e53d1ad079d6e6d3",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://hf-mirror.com/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'entity_group': 'PER',\n  'score': 0.9981694,\n  'word': 'Sylvain',\n  'start': 11,\n  'end': 18},\n {'entity_group': 'ORG',\n  'score': 0.9796019,\n  'word': 'Hugging Face',\n  'start': 33,\n  'end': 45},\n {'entity_group': 'LOC',\n  'score': 0.9932106,\n  'word': 'Brooklyn',\n  'start': 49,\n  'end': 57}]"
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://hf-mirror.com/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/root/miniconda3/envs/nlp_learn/lib/python3.11/site-packages/transformers/pipelines/token_classification.py:168: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'entity_group': 'PER',\n  'score': 0.9981694,\n  'word': 'Sylvain',\n  'start': 11,\n  'end': 18},\n {'entity_group': 'ORG',\n  'score': 0.9796019,\n  'word': 'Hugging Face',\n  'start': 33,\n  'end': 45},\n {'entity_group': 'LOC',\n  'score': 0.9932106,\n  'word': 'Brooklyn',\n  'start': 49,\n  'end': 57}]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner = pipeline(\"ner\", grouped_entities=True,device=0)\n",
    "ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T12:59:52.129766Z",
     "start_time": "2024-03-18T12:59:49.353607Z"
    }
   },
   "id": "507fef23c7c5b615",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'entity_group': 'PER',\n  'score': 0.8838808,\n  'word': 'LingTao',\n  'start': 11,\n  'end': 18}]"
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "[{'entity_group': 'PER',\n  'score': 0.8838808,\n  'word': 'LingTao',\n  'start': 11,\n  'end': 18}]"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner(\"My name is LingTao\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T12:59:52.152727Z",
     "start_time": "2024-03-18T12:59:52.131300Z"
    }
   },
   "id": "81bb7c81f5ffcf07",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://hf-mirror.com/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://hf-mirror.com/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "question_answerer = pipeline(\"question-answering\",device=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T12:59:53.481989Z",
     "start_time": "2024-03-18T12:59:52.154918Z"
    }
   },
   "id": "309dad46ca41e85a",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://hf-mirror.com/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://hf-mirror.com/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T12:59:54.751246Z",
     "start_time": "2024-03-18T12:59:53.484070Z"
    }
   },
   "id": "92c7b5b4f040272e",
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 实体识别 shibing624/bert4ner-base-chinese"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc5340f2b8ae0392"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ner = pipeline(\"ner\", model=\"shibing624/bert4ner-base-chinese\",device=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T12:59:55.723914Z",
     "start_time": "2024-03-18T12:59:54.753908Z"
    }
   },
   "id": "43fabc180279b8f3",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'entity': 'B-PER',\n  'score': 0.99982256,\n  'index': 3,\n  'word': '孔',\n  'start': 2,\n  'end': 3},\n {'entity': 'I-PER',\n  'score': 0.9998381,\n  'index': 4,\n  'word': '令',\n  'start': 3,\n  'end': 4},\n {'entity': 'I-PER',\n  'score': 0.99990463,\n  'index': 5,\n  'word': '涛',\n  'start': 4,\n  'end': 5},\n {'entity': 'B-ORG',\n  'score': 0.99617827,\n  'index': 11,\n  'word': '西',\n  'start': 10,\n  'end': 11},\n {'entity': 'I-ORG',\n  'score': 0.99722326,\n  'index': 12,\n  'word': '安',\n  'start': 11,\n  'end': 12},\n {'entity': 'I-ORG',\n  'score': 0.9936413,\n  'index': 13,\n  'word': '交',\n  'start': 12,\n  'end': 13},\n {'entity': 'I-ORG',\n  'score': 0.9962859,\n  'index': 14,\n  'word': '大',\n  'start': 13,\n  'end': 14}]"
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "[{'entity': 'B-PER',\n  'score': 0.99982256,\n  'index': 3,\n  'word': '孔',\n  'start': 2,\n  'end': 3},\n {'entity': 'I-PER',\n  'score': 0.9998381,\n  'index': 4,\n  'word': '令',\n  'start': 3,\n  'end': 4},\n {'entity': 'I-PER',\n  'score': 0.99990463,\n  'index': 5,\n  'word': '涛',\n  'start': 4,\n  'end': 5},\n {'entity': 'B-ORG',\n  'score': 0.99617827,\n  'index': 11,\n  'word': '西',\n  'start': 10,\n  'end': 11},\n {'entity': 'I-ORG',\n  'score': 0.99722326,\n  'index': 12,\n  'word': '安',\n  'start': 11,\n  'end': 12},\n {'entity': 'I-ORG',\n  'score': 0.9936413,\n  'index': 13,\n  'word': '交',\n  'start': 12,\n  'end': 13},\n {'entity': 'I-ORG',\n  'score': 0.9962859,\n  'index': 14,\n  'word': '大',\n  'start': 13,\n  'end': 14}]"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner(\"我是孔令涛硕士，来自西安交大。\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T12:59:55.760119Z",
     "start_time": "2024-03-18T12:59:55.726382Z"
    }
   },
   "id": "a00681dac1859007",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple/\r\n",
      "Requirement already satisfied: sacremoses in ./miniconda3/lib/python3.10/site-packages (0.1.1)\r\n",
      "Requirement already satisfied: regex in ./miniconda3/lib/python3.10/site-packages (from sacremoses) (2023.10.3)\r\n",
      "Requirement already satisfied: click in ./miniconda3/lib/python3.10/site-packages (from sacremoses) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in ./miniconda3/lib/python3.10/site-packages (from sacremoses) (1.3.2)\r\n",
      "Requirement already satisfied: tqdm in ./miniconda3/lib/python3.10/site-packages (from sacremoses) (4.66.1)\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0mLooking in indexes: http://mirrors.aliyun.com/pypi/simple/\r\n",
      "Requirement already satisfied: sacremoses in /root/miniconda3/lib/python3.10/site-packages (0.1.1)\r\n",
      "Requirement already satisfied: regex in /root/miniconda3/lib/python3.10/site-packages (from sacremoses) (2023.10.3)\r\n",
      "Requirement already satisfied: click in /root/miniconda3/lib/python3.10/site-packages (from sacremoses) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /root/miniconda3/lib/python3.10/site-packages (from sacremoses) (1.3.2)\r\n",
      "Requirement already satisfied: tqdm in /root/miniconda3/lib/python3.10/site-packages (from sacremoses) (4.66.1)\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install sacremoses "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T12:59:59.024785Z",
     "start_time": "2024-03-18T12:59:55.762118Z"
    }
   },
   "id": "33278eae80d7cfd0",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'translation_text': 'Ce cours es est produit at cugging face. 塞斯·库尔斯和罗迪特·拉格脸'}]"
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "[{'translation_text': 'Ce cours es est produit at cugging face. 塞斯·库尔斯和罗迪特·拉格脸'}]"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-zh\",device=0)\n",
    "translator(\"Ce cours est produit par Hugging Face.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T13:00:02.768341Z",
     "start_time": "2024-03-18T12:59:59.036929Z"
    }
   },
   "id": "6e97b26d7705e907",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'translation_text': '我喜欢吃苹果'}]"
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "[{'translation_text': '我喜欢吃苹果'}]"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(\"I like eat apples\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T13:00:02.880309Z",
     "start_time": "2024-03-18T13:00:02.770467Z"
    }
   },
   "id": "b65b38f0515977af",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-zh-en\",device=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T13:00:05.045859Z",
     "start_time": "2024-03-18T13:00:02.884653Z"
    }
   },
   "id": "f9cec190baa9a123",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'translation_text': \"I'm Yang Yiu.\"}]"
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "[{'translation_text': \"I'm Yang Yiu.\"}]"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(\"我是孔令涛硕士。\")\n",
    "translator(\"我是杨烨。\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T13:00:05.312671Z",
     "start_time": "2024-03-18T13:00:05.048833Z"
    }
   },
   "id": "9d4be0932314c83f",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['carpenter', 'lawyer', 'farmer', 'businessman', 'doctor']\n",
      "['nurse', 'maid', 'teacher', 'waitress', 'prostitute']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['carpenter', 'lawyer', 'farmer', 'businessman', 'doctor']\n",
      "['nurse', 'maid', 'teacher', 'waitress', 'prostitute']\n"
     ]
    }
   ],
   "source": [
    "unmasker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
    "result = unmasker(\"This man works as a [MASK].\")\n",
    "print([r[\"token_str\"] for r in result])\n",
    "\n",
    "result = unmasker(\"This woman works as a [MASK].\")\n",
    "print([r[\"token_str\"] for r in result])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T13:00:06.596540Z",
     "start_time": "2024-03-18T13:00:05.314958Z"
    }
   },
   "id": "9aab669274326fba",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['谁', '他', 'ceo', '你', '人']\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "bert-base-chinese does not appear to have a file named config.json. Checkout 'https://huggingface.co/bert-base-chinese/None' for available files.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[33], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m unmasker \u001B[38;5;241m=\u001B[39m \u001B[43mpipeline\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfill-mask\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbert-base-chinese\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m result \u001B[38;5;241m=\u001B[39m unmasker(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m小明长大以后想成为 [MASK].\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m([r[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtoken_str\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m r \u001B[38;5;129;01min\u001B[39;00m result])\n",
      "File \u001B[0;32m~/miniconda3/envs/nlp_learn/lib/python3.11/site-packages/transformers/pipelines/__init__.py:815\u001B[0m, in \u001B[0;36mpipeline\u001B[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001B[0m\n\u001B[1;32m    812\u001B[0m                 adapter_config \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mload(f)\n\u001B[1;32m    813\u001B[0m                 model \u001B[38;5;241m=\u001B[39m adapter_config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbase_model_name_or_path\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m--> 815\u001B[0m     config \u001B[38;5;241m=\u001B[39m \u001B[43mAutoConfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    816\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_from_pipeline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcode_revision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcode_revision\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\n\u001B[1;32m    817\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    818\u001B[0m     hub_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_commit_hash\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39m_commit_hash\n\u001B[1;32m    820\u001B[0m custom_tasks \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[0;32m~/miniconda3/envs/nlp_learn/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py:1111\u001B[0m, in \u001B[0;36mAutoConfig.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[0m\n\u001B[1;32m   1108\u001B[0m trust_remote_code \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrust_remote_code\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m   1109\u001B[0m code_revision \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode_revision\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m-> 1111\u001B[0m config_dict, unused_kwargs \u001B[38;5;241m=\u001B[39m \u001B[43mPretrainedConfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_config_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1112\u001B[0m has_remote_code \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto_map\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config_dict \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAutoConfig\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto_map\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1113\u001B[0m has_local_code \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_type\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config_dict \u001B[38;5;129;01mand\u001B[39;00m config_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_type\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;129;01min\u001B[39;00m CONFIG_MAPPING\n",
      "File \u001B[0;32m~/miniconda3/envs/nlp_learn/lib/python3.11/site-packages/transformers/configuration_utils.py:633\u001B[0m, in \u001B[0;36mPretrainedConfig.get_config_dict\u001B[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[0m\n\u001B[1;32m    631\u001B[0m original_kwargs \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mdeepcopy(kwargs)\n\u001B[1;32m    632\u001B[0m \u001B[38;5;66;03m# Get config dict associated with the base config file\u001B[39;00m\n\u001B[0;32m--> 633\u001B[0m config_dict, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_config_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    634\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_commit_hash\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config_dict:\n\u001B[1;32m    635\u001B[0m     original_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_commit_hash\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m config_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_commit_hash\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/miniconda3/envs/nlp_learn/lib/python3.11/site-packages/transformers/configuration_utils.py:688\u001B[0m, in \u001B[0;36mPretrainedConfig._get_config_dict\u001B[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[0m\n\u001B[1;32m    684\u001B[0m configuration_file \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_configuration_file\u001B[39m\u001B[38;5;124m\"\u001B[39m, CONFIG_NAME)\n\u001B[1;32m    686\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    687\u001B[0m     \u001B[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001B[39;00m\n\u001B[0;32m--> 688\u001B[0m     resolved_config_file \u001B[38;5;241m=\u001B[39m \u001B[43mcached_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    689\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    690\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfiguration_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    691\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    692\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    693\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    694\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    695\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    696\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    697\u001B[0m \u001B[43m        \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    698\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    699\u001B[0m \u001B[43m        \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    700\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_commit_hash\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcommit_hash\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    701\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    702\u001B[0m     commit_hash \u001B[38;5;241m=\u001B[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m:\n\u001B[1;32m    704\u001B[0m     \u001B[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001B[39;00m\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;66;03m# the original exception.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/nlp_learn/lib/python3.11/site-packages/transformers/utils/hub.py:369\u001B[0m, in \u001B[0;36mcached_file\u001B[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001B[0m\n\u001B[1;32m    367\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misfile(resolved_file):\n\u001B[1;32m    368\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _raise_exceptions_for_missing_entries:\n\u001B[0;32m--> 369\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[1;32m    370\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not appear to have a file named \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfull_filename\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Checkout \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    371\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://huggingface.co/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrevision\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m for available files.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    372\u001B[0m         )\n\u001B[1;32m    373\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    374\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mOSError\u001B[0m: bert-base-chinese does not appear to have a file named config.json. Checkout 'https://huggingface.co/bert-base-chinese/None' for available files."
     ]
    }
   ],
   "source": [
    "unmasker = pipeline(\"fill-mask\", model=\"bert-base-chinese\")\n",
    "result = unmasker(\"小明长大以后想成为 [MASK].\")\n",
    "print([r[\"token_str\"] for r in result])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T13:00:07.107727Z",
     "start_time": "2024-03-18T13:00:06.598391Z"
    }
   },
   "id": "d6f721e3c1ea37e3",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    }
   ],
   "source": [
    "# 初始化zero-shot分类管道\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"bert-base-chinese\")\n",
    "\n",
    "# 定义候选标签\n",
    "candidate_labels = ['教育', '政治', '娱乐', '美食']\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T05:45:55.861251Z",
     "start_time": "2024-03-17T05:45:55.407823Z"
    }
   },
   "id": "ad442b4fd0c01ca4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': '英语课是必修课', 'labels': ['娱乐', '美食', '教育', '政治'], 'scores': [0.3618292212486267, 0.26551303267478943, 0.19177424907684326, 0.1808834671974182]}\n"
     ]
    }
   ],
   "source": [
    "# 对文本进行分类\n",
    "result = classifier(\"英语课是必修课\", candidate_labels=candidate_labels)\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T05:44:48.944679Z",
     "start_time": "2024-03-17T05:44:47.898601Z"
    }
   },
   "id": "3b4f072cddb2aa2b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e85db6b7f5b25dd3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
